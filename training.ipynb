{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import librosa\n",
    "from librosa.feature import melspectrogram\n",
    "import warnings\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from PIL import Image\n",
    "from uuid import uuid4\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, LSTM, SimpleRNN, Conv1D, Input, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "#from keras_efficientnets import EfficientNetB0\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we first create two dictionaries to allow to translate each bird into an ID code and vice versa. As we won't be able to use the entirety of the data in this notebook for processing time reasons, we will shuffle the `DataFrame` with the training data before preparing the data. We will then create a new `DataFrame` where we will store all the samples, of 5 seconds each with a sampling rate of 10 data points per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('nachtall_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like each ebird is associated with a \"reasonable\" amount of samples. We only keep the bird species with 100 samples of the highest quality (4 or 5) to make the problem easier to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['House Sparrow', 'Common Blackbird', 'Great Tit', 'Common Starling', 'Eurasian Blue Tit', 'Eurasian Tree Sparrow', 'Eurasian Magpie', 'Common Wood Pigeon', 'European Robin', 'Common House Martin', 'Common Swift', 'Carrion Crow', 'Common Chaffinch', 'Eurasian Collared Dove', 'European Goldfinch', 'Great Spotted Woodpecker', 'Barn Swallow', 'Eurasian Jay', 'Rock Dove', 'Eurasian Bullfinch']\n"
     ]
    }
   ],
   "source": [
    "#birds_to_recognise = sorted(shuffle(most_represented_birds)[:20])\n",
    "birds_to_recognise = ['House Sparrow', 'Common Blackbird', 'Great Tit', 'Common Starling', 'Eurasian Blue Tit', 'Eurasian Tree Sparrow', 'Eurasian Magpie', 'Common Wood Pigeon', 'European Robin', 'Common House Martin', 'Common Swift', 'Carrion Crow', 'Common Chaffinch', 'Eurasian Collared Dove', 'European Goldfinch', 'Great Spotted Woodpecker', 'Barn Swallow', 'Eurasian Jay', 'Rock Dove', 'Eurasian Bullfinch']\n",
    "print(birds_to_recognise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(filename, bird, output_folder):\n",
    "    wave_data, wave_rate = librosa.load(filename)\n",
    "    wave_data, _ = librosa.effects.trim(wave_data)\n",
    "    #only take 5s samples and add them to the dataframe\n",
    "    song_sample = []\n",
    "    sample_length = 2*wave_rate\n",
    "    samples_from_file = []\n",
    "    #The variable below is chosen mainly to create a 216x216 image\n",
    "    N_mels=216\n",
    "    for idx in range(0,len(wave_data),sample_length): \n",
    "        song_sample = wave_data[idx:idx+sample_length]\n",
    "        if len(song_sample)>=sample_length:\n",
    "            mel = melspectrogram(song_sample, n_mels=N_mels)\n",
    "            db = librosa.power_to_db(mel)\n",
    "            normalised_db = sklearn.preprocessing.minmax_scale(db)\n",
    "            filename = str(uuid4())+\".tif\"\n",
    "            db_array = (np.asarray(normalised_db)*255).astype(np.uint8)\n",
    "            db_image =  Image.fromarray(np.array([db_array, db_array, db_array]).T)\n",
    "            db_image.save(\"{}{}\".format(output_folder,filename))\n",
    "            \n",
    "            samples_from_file.append({\"song_sample\":\"{}{}\".format(output_folder,filename),\n",
    "                                            \"bird\":bird})\n",
    "    return samples_from_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will set all the samples with non-selected birds to the \"nocall\" ID code. This allows to focus on the classification of the 5 selected bird species while all of bird species will be categorised as \"nocall\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8%|â–Š         | 75/1000 [02:28<30:35,  1.98s/it]CPU times: user 3min 50s, sys: 5min 36s, total: 9min 27s\n",
      "Wall time: 2min 28s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "samples_df = pd.DataFrame(columns=[\"song_sample\",\"bird\"])\n",
    "\n",
    "#We limit the number of audio files being sampled to 1000 in this notebook to save time\n",
    "#on top of having limited the number of bird species previously\n",
    "#SETTING LIMIT FROM 1000 to 100 for test\n",
    "sample_limit = 1000\n",
    "sample_list = []\n",
    "\n",
    "output_folder = \"/home/dvm/Schreibtisch/nachtall_Code/Data_training/melspectrogram_dataset\"\n",
    "#os.mkdir(output_folder)\n",
    "with tqdm(total=sample_limit) as pbar:\n",
    "    for idx, row in train_df[:sample_limit].iterrows():\n",
    "        pbar.update(1)\n",
    "        try:\n",
    "            audio_file_path = \"/home/dvm/Schreibtisch/nachtall_Code/Data_training/songs\"\n",
    "            #audio_file_path += row.ebird_code\n",
    "            \n",
    "            if row.ebird_code in birds_to_recognise:\n",
    "                sample_list += get_sample('{}/{}'.format(audio_file_path, row.filename), row.ebird_code, output_folder)\n",
    "            else:\n",
    "                sample_list += get_sample('{}/{}'.format(audio_file_path, row.filename), \"nocall\", output_folder)\n",
    "        except:\n",
    "            raise\n",
    "            print(\"{} is corrupted\".format(audio_file_path))\n",
    "            \n",
    "samples_df = pd.DataFrame(sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.DataFrame(sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df.to_hdf('data.h5', key='df', mode='w')\n",
    "\n",
    "#store = pd.HDFStore('data.h5')\n",
    "#store['samples_df'] = samples_df  # save it\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.read_hdf('data.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "store['samples_df']  # load it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_img = Image.open(samples_df.iloc[0].song_sample)\n",
    "plt.imshow(demo_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_sample</th>\n",
       "      <th>bird</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>melspectrogram_dataset0edad534-2ecf-48fc-b937-...</td>\n",
       "      <td>European Robin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>melspectrogram_datasetdcc1bd49-d201-4268-9138-...</td>\n",
       "      <td>Common Chaffinch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>melspectrogram_dataset6d04a807-f598-4e2e-8f8c-...</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>melspectrogram_dataset77975aee-24ff-464d-b132-...</td>\n",
       "      <td>Eurasian Jay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>melspectrogram_dataset9d7d0eb2-3d0a-4ee8-8bb5-...</td>\n",
       "      <td>Common Blackbird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>melspectrogram_datasetfd01c292-3383-4c2e-84ee-...</td>\n",
       "      <td>Common Blackbird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>melspectrogram_datasetade59988-6b63-47ba-b903-...</td>\n",
       "      <td>Barn Swallow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>melspectrogram_dataset260dba3f-7918-4772-aa91-...</td>\n",
       "      <td>Common Blackbird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>melspectrogram_dataset4d29daa5-c9f4-455d-a37e-...</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>melspectrogram_dataset90391441-3e89-461b-bc45-...</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            song_sample              bird\n",
       "986   melspectrogram_dataset0edad534-2ecf-48fc-b937-...    European Robin\n",
       "1386  melspectrogram_datasetdcc1bd49-d201-4268-9138-...  Common Chaffinch\n",
       "2332  melspectrogram_dataset6d04a807-f598-4e2e-8f8c-...            nocall\n",
       "1885  melspectrogram_dataset77975aee-24ff-464d-b132-...      Eurasian Jay\n",
       "211   melspectrogram_dataset9d7d0eb2-3d0a-4ee8-8bb5-...  Common Blackbird\n",
       "79    melspectrogram_datasetfd01c292-3383-4c2e-84ee-...  Common Blackbird\n",
       "1700  melspectrogram_datasetade59988-6b63-47ba-b903-...      Barn Swallow\n",
       "100   melspectrogram_dataset260dba3f-7918-4772-aa91-...  Common Blackbird\n",
       "2505  melspectrogram_dataset4d29daa5-c9f4-455d-a37e-...            nocall\n",
       "2094  melspectrogram_dataset90391441-3e89-461b-bc45-...            nocall"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_df = shuffle(samples_df)\n",
    "samples_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_percentage = 0.9\n",
    "training_item_count = int(len(samples_df)*training_percentage)\n",
    "validation_item_count = len(samples_df)-int(len(samples_df)*training_percentage)\n",
    "training_df = samples_df[:training_item_count]\n",
    "validation_df = samples_df[training_item_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ON!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in this [post](https://www.kaggle.com/c/birdsong-recognition/discussion/158943) by [Nanashi](https://www.kaggle.com/jesucristo), CNN-based models seem to outperform LSTM-based models for this type of tasks. Therefore, we will use the freshly added EfficientNet models from Tensorflow 2.3.0.\n",
    "\n",
    "Also, I have realised that we can have several birds singing at the same time in our samples, which means that we will have to change the output layer and loss to have several possible outputs and not just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb0 (Functional)  (None, 7, 7, 1280)        4049571   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               327680    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 21)                5397      \n",
      "=================================================================\n",
      "Total params: 4,383,672\n",
      "Trainable params: 4,341,137\n",
      "Non-trainable params: 42,535\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classes_to_predict = sorted(samples_df.bird.unique())\n",
    "#classes_to_predict = birds_to_recognise\n",
    "input_shape = (216,216, 3)\n",
    "effnet_layers = EfficientNetB0(weights=None, include_top=False, input_shape=input_shape)\n",
    "\n",
    "for layer in effnet_layers.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "dropout_dense_layer = 0.3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(effnet_layers)\n",
    "    \n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_dense_layer))\n",
    "\n",
    "model.add(Dense(len(classes_to_predict), activation=\"softmax\"))\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.7),\n",
    "             EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='model/best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##OFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight(\"balanced\", classes_to_predict, samples_df.bird.values)\n",
    "class_weights_dict = {i : class_weights[i] for i,label in enumerate(classes_to_predict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "#orig. 32\n",
    "#training_batch_size = 32\n",
    "#validation_batch_size = 32\n",
    "training_batch_size = 32\n",
    "validation_batch_size = 32\n",
    "target_size = (216,216)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = training_df,\n",
    "    x_col='song_sample',\n",
    "    y_col='bird',\n",
    "    directory='/',\n",
    "    target_size=target_size,\n",
    "    batch_size=training_batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe = validation_df,\n",
    "    x_col='song_sample',\n",
    "    y_col='bird',\n",
    "    directory='/',\n",
    "    target_size=target_size,\n",
    "    shuffle=False,\n",
    "    batch_size=validation_batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, I will comment out the class weights as I don't mind training a model that will be biased to \"nocall\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Asked to retrieve element 0, but the Sequence has length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-693ce7008145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/home/dvm/anaconda3/envs/nachtall/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dvm/anaconda3/envs/nachtall/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dvm/anaconda3/envs/nachtall/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dvm/anaconda3/envs/nachtall/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dvm/anaconda3/envs/nachtall/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dvm/anaconda3/envs/nachtall/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m   def _handle_multiprocessing(self, x, workers, use_multiprocessing,\n",
      "\u001b[0;32m/home/dvm/anaconda3/envs/nachtall/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     55\u001b[0m                              \u001b[0;34m'but the Sequence '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                              'has length {length}'.format(idx=idx,\n\u001b[0;32m---> 57\u001b[0;31m                                                           length=len(self)))\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_batches_seen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Asked to retrieve element 0, but the Sequence has length 0"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "          epochs = 200, \n",
    "          validation_data=validation_generator,\n",
    "           class_weight=class_weights_dict,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss over epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running predictions on a single batch from our validation set just to check if our model displays any anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model.predict_generator(validation_generator)\n",
    "validation_df = pd.DataFrame(columns=[\"prediction\", \"groundtruth\", \"correct_prediction\"])\n",
    "\n",
    "for pred, groundtruth in zip(preds[:16], validation_generator.__getitem__(0)[1]):\n",
    "    validation_df = validation_df.append({\"prediction\":classes_to_predict[np.argmax(pred)], \n",
    "                                       \"groundtruth\":classes_to_predict[np.argmax(groundtruth)], \n",
    "                                       \"correct_prediction\":np.argmax(pred)==np.argmax(groundtruth)}, ignore_index=True)\n",
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/melspectrogram_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the weights for the best-performing model on our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ON!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model/best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the training samples, we will only load each audio file, generate a melspectrogram for each 5-second sequence and predict on it. This prediction function ensures that we do not reload the .mp3 audio file for every sample as it would significantly increase the processing time. Then, it adds all the predictions to the `test_df` DataFrame before generating the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_melspectrogram(song_sample, sample_length):\n",
    "    N_mels=216\n",
    "\n",
    "    if len(song_sample)>=sample_length:\n",
    "        mel = melspectrogram(song_sample, n_mels=N_mels)\n",
    "        db = librosa.power_to_db(mel)\n",
    "        normalised_db = sklearn.preprocessing.minmax_scale(db)\n",
    "        db_array = (np.asarray(normalised_db)*255).astype(np.uint8)\n",
    "\n",
    "        prediction = model.predict(np.array([np.array([db_array, db_array, db_array]).T]))\n",
    "        predicted_bird = classes_to_predict[np.argmax(prediction)]\n",
    "        return predicted_bird\n",
    "    else:\n",
    "        return \"nocall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "wave_data, wave_rate = librosa.load('songs/xc116226.flac')\n",
    "sample_length = 2*wave_rate\n",
    "\n",
    "song_sample = np.array(wave_data[0:sample_length])\n",
    "\n",
    "predicted_bird = predict_on_melspectrogram(song_sample, sample_length)\n",
    "print(predicted_bird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_submission(df, audio_file_path):\n",
    "        \n",
    "    loaded_audio_sample = []\n",
    "    previous_filename = \"\"\n",
    "    wave_data = []\n",
    "    wave_rate = None\n",
    "    sample_length = None\n",
    "    \n",
    "    for idx,row in df.iterrows():\n",
    "        #I added this exception as I've heard that some files may be corrupted.\n",
    "        try:\n",
    "            if previous_filename == \"\" or previous_filename!=row.audio_id:\n",
    "                filename = '{}/{}.mp3'.format(audio_file_path, row.audio_id)\n",
    "                wave_data, wave_rate = librosa.load(filename)\n",
    "                sample_length = 5*wave_rate\n",
    "            previous_filename = row.audio_id\n",
    "\n",
    "            #basically allows to check if we are running the examples or the test set.\n",
    "            if \"site\" in df.columns:\n",
    "                if row.site==\"site_1\" or row.site==\"site_2\":\n",
    "                    song_sample = np.array(wave_data[int(row.seconds-5)*wave_rate:int(row.seconds)*wave_rate])\n",
    "                elif row.site==\"site_3\":\n",
    "                    #for now, I only take the first 5s of the samples from site_3 as they are groundtruthed at file level\n",
    "                    song_sample = np.array(wave_data[0:sample_length])\n",
    "            else:\n",
    "                #same as the first condition but I isolated it for later and it is for the example file\n",
    "                song_sample = np.array(wave_data[int(row.seconds-5)*wave_rate:int(row.seconds)*wave_rate])\n",
    "            \n",
    "            predicted_bird = predict_on_melspectrogram(song_sample, sample_length)\n",
    "            df.at[idx,\"birds\"] = predicted_bird\n",
    "        except:\n",
    "            df.at[idx,\"birds\"] = \"nocall\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, We can test our prediction function using the examples provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = \"/example_test_audio\"\n",
    "example_df = pd.read_csv(\"example_test_audio_summary.csv\")\n",
    "#Ajusting the example filenames and creating the audio_id column to match with the test file.\n",
    "example_df[\"audio_id\"] = [ \"BLKFR-10-CPL_20190611_093000.pt540\" if filename==\"BLKFR-10-CPL\" else \"ORANGE-7-CAP_20190606_093000.pt623\" for filename in example_df[\"filename\"]]\n",
    "\n",
    "if os.path.exists(audio_file_path):\n",
    "    example_df = predict_submission(example_df, audio_file_path)\n",
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = \"/test_audio\"\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "submission_df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "if os.path.exists(test_file_path):\n",
    "    submission_df = predict_submission(test_df, test_file_path)\n",
    "\n",
    "submission_df[[\"row_id\",\"birds\"]].to_csv('submission.csv', index=False)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thanks for reading this notebook! If you found this notebook helpful, please give it an upvote. It is always greatly appreciated!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}